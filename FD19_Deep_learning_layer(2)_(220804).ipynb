{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdKDuARDXAHyxE5F51TM1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgr1118/FD/blob/main/FD19_Deep_learning_layer(2)_(220804).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P-Q7bFEiJ7e",
        "outputId": "def6b4d1-d87f-4ae3-cbf5-ec6187e28af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# 19-3. 단어를 부탁해! Embedding 레이어\n",
        "# 원-핫 벡터 생성\n",
        "import tensorflow as tf\n",
        "\n",
        "vocab = {      # 사용할 단어 사전 정의\n",
        "    \"i\": 0,\n",
        "    \"need\": 1,\n",
        "    \"some\": 2,\n",
        "    \"more\": 3,\n",
        "    \"coffee\": 4,\n",
        "    \"cake\": 5,\n",
        "    \"cat\": 6,\n",
        "    \"dog\": 7}\n",
        "\n",
        "sentence = 'i i i i need some more coffee coffee coffee'\n",
        "# 위 sentence\n",
        "_input = [vocab[w] for w in sentence.split()]  # [0, 0, 0, 0, 1, 2, 3, 4, 4, 4]\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "one_hot = tf.one_hot(_input, vocab_size)\n",
        "print(one_hot.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear 레이어에 원-핫 벡터를 넣어보기\n",
        "distribution_size = 2 # 2차원으로 분산 표현\n",
        "linear = tf.keras.layers.Dense(units=distribution_size, use_bias=False)\n",
        "one_hot_linear = linear(one_hot)\n",
        "\n",
        "print(\"Linear Weight\")\n",
        "print(linear.weights[0].numpy())\n",
        "\n",
        "print(\"\\nOne-Hot Linear Result\")\n",
        "print(one_hot_linear.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEZ4iUW9i74-",
        "outputId": "169d3e4a-7f78-46a6-dce0-6a22df94fc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Weight\n",
            "[[ 0.44856846 -0.32948077]\n",
            " [-0.22136456 -0.15440005]\n",
            " [ 0.3260082  -0.27210563]\n",
            " [-0.7019764   0.09530932]\n",
            " [-0.47168928  0.5753845 ]\n",
            " [ 0.17575365 -0.6628198 ]\n",
            " [ 0.7413982   0.7616451 ]\n",
            " [ 0.12514794 -0.74043435]]\n",
            "\n",
            "One-Hot Linear Result\n",
            "[[ 0.44856846 -0.32948077]\n",
            " [ 0.44856846 -0.32948077]\n",
            " [ 0.44856846 -0.32948077]\n",
            " [ 0.44856846 -0.32948077]\n",
            " [-0.22136456 -0.15440005]\n",
            " [ 0.3260082  -0.27210563]\n",
            " [-0.7019764   0.09530932]\n",
            " [-0.47168928  0.5753845 ]\n",
            " [-0.47168928  0.5753845 ]\n",
            " [-0.47168928  0.5753845 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding 레이어의 입력으로 넣어주는 처리\n",
        "some_words = tf.constant([[3, 57, 35]])\n",
        "# 3번 단어 / 57번 단어 / 35번 단어로 이루어진 한 문장입니다.\n",
        "\n",
        "print(\"Embedding을 진행할 문장:\", some_words.shape)\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=64, output_dim=100)\n",
        "# 총 64개의 단어를 포함한 Embedding 레이어를 선언할 것이고,\n",
        "# 각 단어는 100차원으로 분산 표현 할 것입니다.\n",
        "\n",
        "print(\"Embedding된 문장:\", embedding_layer(some_words).shape)\n",
        "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mChycdUaj09e",
        "outputId": "55e11272-949b-4a26-c2ed-6e3d1aa582f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding을 진행할 문장: (1, 3)\n",
            "Embedding된 문장: (1, 3, 100)\n",
            "Embedding Layer의 Weight 형태: (64, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding 레이어 주의사항\n",
        "#### 기본적으로 딥러닝은 미분을 기반으로 동작한다. Embedding 레이어는 단어를 대응만 시켜줄 뿐이니 미분이 불가능하다.\n",
        "\n",
        "#### 신경망 설계를 할 때 연산 결과에 Embedding 레이어에 연결시키는 것은 불가능\n",
        "\n",
        "#### Embedding 레이어는 입력에 직접 연결되게 사용해야 한다는 것을 꼭 기억\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zTqkVjh7kV2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 19-4. 순차적인 데이터! Recurrent 레이어 (1) RNN\n",
        "sentence = \"What time is it ?\"\n",
        "dic = {\n",
        "    \"is\": 0,\n",
        "    \"it\": 1,\n",
        "    \"What\": 2,\n",
        "    \"time\": 3,\n",
        "    \"?\": 4}\n",
        "\n",
        "print('RNN에 입력할 문장:', sentence)\n",
        "\n",
        "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
        "\n",
        "print('Embedding을 위해 단어 매핑:', sentence_tensor.numpy())\n",
        "print('입력 문장 데이터 형태:', sentence_tensor.shape)\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
        "emb_out = embedding_layer(sentence_tensor)\n",
        "\n",
        "print(\"\\nEmbedding 결과:\", emb_out.shape)\n",
        "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)\n",
        "\n",
        "rnn_seq_layer = \\\n",
        "tf.keras.layers.SimpleRNN(units=64, return_sequences=True, use_bias=False)\n",
        "rnn_seq_out = rnn_seq_layer(emb_out)\n",
        "\n",
        "print(\"\\nRNN 결과 (모든 Step Output):\", rnn_seq_out.shape)\n",
        "print(\"RNN Layer의 Weight 형태:\", rnn_seq_layer.weights[0].shape)\n",
        "\n",
        "rnn_fin_layer = tf.keras.layers.SimpleRNN(units=64, use_bias=False)\n",
        "rnn_fin_out = rnn_fin_layer(emb_out)\n",
        "\n",
        "print(\"\\nRNN 결과 (최종 Step Output):\", rnn_fin_out.shape)\n",
        "print(\"RNN Layer의 Weight 형태:\", rnn_fin_layer.weights[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yzi7G2pqqok",
        "outputId": "42ebbcce-64ea-4e71-d56b-5864a749f980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN에 입력할 문장: What time is it ?\n",
            "Embedding을 위해 단어 매핑: [[2 3 0 1 4]]\n",
            "입력 문장 데이터 형태: (1, 5)\n",
            "\n",
            "Embedding 결과: (1, 5, 100)\n",
            "Embedding Layer의 Weight 형태: (5, 100)\n",
            "\n",
            "RNN 결과 (모든 Step Output): (1, 5, 64)\n",
            "RNN Layer의 Weight 형태: (100, 64)\n",
            "\n",
            "RNN 결과 (최종 Step Output): (1, 64)\n",
            "RNN Layer의 Weight 형태: (100, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SimpleRNN 레이어의 return_sequences 인자를 조절\n",
        "lstm_seq_layer = tf.keras.layers.LSTM(units=64, return_sequences=True, use_bias=False)\n",
        "lstm_seq_out = lstm_seq_layer(emb_out)\n",
        "\n",
        "print(\"\\nLSTM 결과 (모든 Step Output):\", lstm_seq_out.shape)\n",
        "print(\"LSTM Layer의 Weight 형태:\", lstm_seq_layer.weights[0].shape)\n",
        "\n",
        "lstm_fin_layer = tf.keras.layers.LSTM(units=64, use_bias=False)\n",
        "lstm_fin_out = lstm_fin_layer(emb_out)\n",
        "\n",
        "print(\"\\nLSTM 결과 (최종 Step Output):\", lstm_fin_out.shape)\n",
        "print(\"LSTM Layer의 Weight 형태:\", lstm_fin_layer.weights[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH5o2Ez52wo1",
        "outputId": "e7a0bef9-db1c-4ac5-f6e4-a115db8fd9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LSTM 결과 (모든 Step Output): (1, 5, 64)\n",
            "LSTM Layer의 Weight 형태: (100, 256)\n",
            "\n",
            "LSTM 결과 (최종 Step Output): (1, 64)\n",
            "LSTM Layer의 Weight 형태: (100, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 19-5. 순차적인 데이터! Recurrent 레이어 (2) LSTM\n",
        "\n",
        "# 양방향 RNN\n",
        "import tensorflow as tf\n",
        "\n",
        "sentence = 'What time is it ?'\n",
        "dic = {\n",
        "    \"is\": 0,\n",
        "    \"it\": 1,\n",
        "    \"What\": 2,\n",
        "    \"time\": 3,\n",
        "    \"?\": 4}\n",
        "\n",
        "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
        "emb_out = embedding_layer(sentence_tensor)\n",
        "\n",
        "print('입력 문장 데이터 형태:', emb_out.shape)\n",
        "\n",
        "bi_rnn = \\\n",
        "tf.keras.layers.Bidirectional(\n",
        "    tf.keras.layers.SimpleRNN(units=64, use_bias=False, return_sequences=True))\n",
        "\n",
        "bi_out = bi_rnn(emb_out)\n",
        "\n",
        "print(\"Bidirectional RNN 결과 (최종 Step Output):\", bi_out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE5wRwIJ35ND",
        "outputId": "b58933e7-9307-4729-edbb-d4212e399211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장 데이터 형태: (1, 5, 100)\n",
            "Bidirectional RNN 결과 (최종 Step Output): (1, 5, 128)\n"
          ]
        }
      ]
    }
  ]
}